{"date":"Thu Dec 22 12:47:32 EST 2016","section":"Magazine","abstract":"The social-media giant is trying to combat the scourge of bogus stories on its site. But its methods suggest a continuation of its efforts to subsume the entire internet.","title":"Facebook\u2019s Problem Isn\u2019t Fake News \u2014 It\u2019s the Rest of the Internet","body":" Last Thursday, after weeks of criticism over its role in the proliferation of falsehoods and propaganda during the presidential election, Facebook announced its plan to combat \u201choaxes\u201d and \u201cfake news.\u201d The company promised to test new tools that would allow users to report misinformation, and to enlist fact-checking organizations including Snopes and PolitiFact to help litigate the veracity of links reported as suspect. By analyzing patterns of reading and sharing, the company said, it might be able to penalize articles that are shared at especially low rates by those who read them \u2014 a signal of dissatisfaction. Finally, it said, it would try to put economic pressure on bad actors in three ways: by banning disputed stories from its advertising ecosystem; by making it harder to impersonate credible sites on the platform; and, crucially, by penalizing websites that are loaded with too many ads. Over the past month the colloquial definition of \u201cfake news\u201d has expanded beyond usefulness, implicating everything from partisan news to satire to conspiracy theories before being turned, finally, back against its creators. Facebook\u2019s fixes address a far more narrow definition. \u201cWe\u2019ve focused our efforts on the worst of the worst, on the clear hoaxes spread by spammers for their own gain,\u201d wrote Adam Mosseri, a vice president for news feed, in a blog post. Facebook\u2019s political news ecosystem during the 2016 election was vast and varied. There was, of course, content created by outside news media that was shared by users, but there were also reams of content \u2014 posts, images, videos \u2014 created on Facebook-only pages, and still more media created by politicians themselves. During the election, it was apparent to almost anyone with an account that Facebook was teeming with political content, much of it extremely partisan or pitched, its sourcing sometimes obvious, other times obscured, and often simply beside the point \u2014 memes or rants or theories that spoke for themselves. Facebook seems to have zeroed in on only one component of this ecosystem \u2014 outside websites \u2014 and within it, narrow types of bad actors. These firms are, generally speaking, paid by advertising companies independent of Facebook, which are unaware of or indifferent to their partners\u2019 sources of audience. Accordingly, Facebook\u2019s anti-hoax measures seek to regulate these sites by punishing them not just for what they do on Facebook, but for what they do outside of it. \u201cWe\u2019ve found that a lot of fake news is financially motivated,\u201d Mosseri wrote. \u201cSpammers make money by masquerading as well-known news organizations and posting hoaxes that get people to visit to their sites, which are often mostly ads.\u201d The proposed solution: \u201cAnalyzing publisher sites to detect where policy enforcement actions might be necessary.\u201d The stated targets of Facebook\u2019s efforts are precisely defined, but its formulation of the problem implicates, to a lesser degree, much more than just \u201cthe worst of the worst.\u201d Consider this characterization of what makes a \u201cfake news\u201d site a bad platform citizen: It uses Facebook to capture receptive audiences by spreading lies and then converts those audiences into money by borrowing them from Facebook, luring them to an outside site larded with obnoxious ads. The site\u2019s sin of fabrication is made worse by its profit motive, which is cast here as a sort of arbitrage scheme. But an acceptable news site does more or less the same thing: It uses Facebook to capture receptive audiences by spreading not-lies and then converts those audiences into money by luring them to an outside site not-quite larded with not-as-obnoxious ads. In either case, Facebook users are being taken out of the safe confines of the platform into areas that Facebook does not and cannot control. In this context, this \u201cfake news\u201d problem reads less as a distinct new phenomenon than as a flaring symptom of an older, more existential anxiety that Facebook has been grappling with for years: its continued (albeit diminishing) dependence on the same outside web that it, and other platforms, have begun to replace. Facebook\u2019s plan for \u201cfake news\u201d is no doubt intended to curb certain types of misinformation. But it\u2019s also a continuation of the company\u2019s bigger and more consequential project \u2014 to capture the experiences of the web it wants and from which it can profit, but to insulate itself from the parts that it doesn\u2019t and can\u2019t. This may help solve a problem within the ecosystem of outside publishers \u2014 an ecosystem that, in the distribution machinery of Facebook, is becoming redundant, and perhaps even obsolete. As Facebook has grown, so have its ambitions. Its mantralike mission (to \u201cconnect the world\u201d) is rivaled among internet companies perhaps by only that of Google (to \u201corganize the world\u2019s information\u201d) in terms of sheer scope. In the run-up to Facebook\u2019s initial public offering, Mark Zuckerberg told investors that the company makes decisions \u201cnot optimizing for what\u2019s going to happen in the next year, but to set us up to really be in this world where every product experience you have is social, and that\u2019s all powered by Facebook.\u201d To understand what such ambition looks like in practice, consider Facebook\u2019s history. It started as an inward-facing website, closed off from both the web around it and the general public. It was a place to connect with other people, and where content was created primarily by other users: photos, wall posts, messages. This system quickly grew larger and more complex, leading to the creation, in 2006, of the news feed \u2014 a single location in which users could find updates from all of their Facebook friends, in roughly reverse-chronological order. When the news feed was announced, before the emergence of the modern Facebook sharing ecosystem, Facebook\u2019s operating definition of \u201cnews\u201d was pointedly friend-centric. \u201cNow, whenever you log in, you\u2019ll get the latest headlines generated by the activity of your friends and social groups,\u201d the announcement about the news feed said. This would soon change. In the ensuing years, as more people spent more time on Facebook, and following the addition of \u201cLike\u201d and \u201cShare\u201d functions within Facebook, the news feed grew into a personalized portal not just for personal updates but also for the cornucopia of media that existed elsewhere online: links to videos, blog posts, games and more or less anything else published on an external website, including news articles. This potent mixture accelerated Facebook\u2019s change from a place for keeping up with family and friends to a place for keeping up, additionally, with the web in general, as curated by your friends and family. Facebook\u2019s purview continued to widen as its user base grew and then acquired their first smartphones; its app became an essential lens through which hundreds of millions of people interacted with one another, with the rest of the web and, increasingly, with the world at large. Facebook, in other words, had become an interface for the whole web rather than just one more citizen of it. By sorting and mediating the internet, Facebook inevitably began to change it. In the previous decade, the popularity of Google influenced how websites worked, in noticeable ways: Titles and headlines were written in search-friendly formats; pages or articles would be published not just to cover the news but, more specifically, to address Google searchers\u2019 queries about the news, the canonical example being The Huffington Post\u2019s famous \u201cWhat Time Does The Super Bowl Start?\u201d Publishers built entire business models around attracting search traffic, and search-engine optimization, S.E.O., became an industry unto itself. Facebook\u2019s influence on the web \u2014 and in particular, on news publishers \u2014 was similarly profound. Publishers began taking into consideration how their headlines, and stories, might travel within Facebook. Some embraced the site as a primary source of visitors; some pursued this strategy into absurdity and exploitation. Facebook, for its part, paid close attention to the sorts of external content people were sharing on its platform and to the techniques used by websites to get an edge. It adapted continually. It provided greater video functionality, reducing the need to link to outside videos or embed them from YouTube. As people began posting more news, it created previews for links, with larger images and headlines and longer summaries; eventually, it created Instant Articles, allowing certain publishers (including The Times) to publish stories natively in Facebook. At the same time, it routinely sought to penalize sites it judged to be using the platform in bad faith, taking aim at \u201cclickbait,\u201d an older cousin of \u201cfake news,\u201d with a series of design and algorithm updates. As Facebook\u2019s influence over online media became unavoidably obvious, its broad approach to users and the web became clearer: If the network became a popular venue for a certain sort of content or behavior, the company generally and reasonably tried to make that behavior easier or that content more accessible. This tended to mean, however, bringing it in-house. To Facebook, the problem with \u201cfake news\u201d is not just the obvious damage to the discourse, but also with the harm it inflicts upon the platform. People sharing hoax stories were, presumably, happy enough with they were seeing. But the people who would then encounter those stories in their feeds were subjected to a less positive experience. They were sent outside the platform to a website where they realized they were being deceived, or where they were exposed to ads or something that felt like spam, or where they were persuaded to share something that might later make them look like a rube. These users might rightly associate these experiences not just with their friends on the platform, or with the sites peddling the bogus stories but also with the platform itself. This created, finally, an obvious issue for a company built on attention, advertising and the promotion of outside brands. From the platform\u2019s perspective, \u201cfake news\u201d is essentially a user-experience problem resulting from a lingering design issue \u2014 akin to slow-loading news websites that feature auto-playing videos and obtrusive ads. Increasingly, legitimacy within Facebook\u2019s ecosystem is conferred according to a participant\u2019s relationship to the platform\u2019s design. A verified user telling a lie, be it a friend from high school or the president elect, isn\u2019t breaking the rules; he is, as his checkmark suggests, who he represents himself to be. A post making false claims about a product is Facebook\u2019s problem only if that post is labeled an ad. A user video promoting a conspiracy theory becomes a problem only when it leads to the violation of community guidelines against, for example, user harassment. Facebook contains a lot more than just news, including a great deal of content that is newslike, partisan, widely shared and often misleading. Content that has been, and will be, immune from current \u201cfake news\u201d critiques and crackdowns, because it never had the opportunity to declare itself news in the first place. To publish lies as \u201cnews\u201d is to break a promise; to publish lies as \u201ccontent\u201d is not. That the \u201cfake news\u201d problem and its proposed solutions have been defined by Facebook as link issues \u2014 as a web issue \u2014 aligns nicely with a longer-term future in which Facebook\u2019s interface with the web is diminished. Indeed, it heralds the coming moment when posts from outside are suspect by default: out of place, inefficient, little better than spam.","url":"http://www.nytimes.com/2016/12/22/magazine/facebooks-problem-isnt-fake-news-its-the-rest-of-the-internet.html"}